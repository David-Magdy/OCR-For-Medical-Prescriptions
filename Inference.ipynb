{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NieMDMOh122r",
        "outputId": "9e414ab7-2dbb-4f77-eae5-a502e7354189"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.120-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\n",
            "Collecting symspellpy\n",
            "  Downloading symspellpy-6.9.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.2)\n",
            "Collecting editdistpy>=0.1.3 (from symspellpy)\n",
            "  Downloading editdistpy-0.1.5-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.120-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading symspellpy-6.9.0-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading editdistpy-0.1.5-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.1/144.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, editdistpy, symspellpy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed editdistpy-0.1.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 symspellpy-6.9.0 ultralytics-8.3.120 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics transformers huggingface_hub symspellpy gdown\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VhuLR8YMc0Xs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import gdown\n",
        "from PIL import Image, ImageOps\n",
        "from ultralytics import YOLO\n",
        "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
        "from huggingface_hub import hf_hub_download\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "MyfytGip9DIa",
        "outputId": "655ba979-8b15-4366-94f7-35d8bae3f81e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1iKhMK4R6HP3kq3v4pLONPXArtVYAPn2D\n",
            "To: c:\\Users\\ahmed\\Desktop\\ME_                ( NOT DAILY)\\hackathons\\STP\\OCR-PIPELINE\\src\\SUBMISSIONS\\database.xlsx\n",
            "100%|██████████| 30.0k/30.0k [00:00<00:00, 707kB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'database.xlsx'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "file_id = \"1iKhMK4R6HP3kq3v4pLONPXArtVYAPn2D\"\n",
        "\n",
        "\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "\n",
        "outputt = \"database.xlsx\"\n",
        "gdown.download(url, outputt, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5zJVqNh3PJV",
        "outputId": "dbeaef6e-2b9a-423f-8ca9-c1f4e4a65b76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fqPNF574m_wR"
      },
      "outputs": [],
      "source": [
        "model_path = hf_hub_download(repo_id=\"wahdan2003/YOLO_handwritten_medical\", filename=\"best.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "w0Z52mKdnR5Q"
      },
      "outputs": [],
      "source": [
        "yolo_model = YOLO(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yC1eVwIdB03",
        "outputId": "e4b44ccf-9427-4bb3-cf4d-49618a7cae9c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"encoder_stride\": 16,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"image_size\": 384,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"model_type\": \"vit\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_channels\": 3,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"patch_size\": 16,\n",
            "  \"pooler_act\": \"tanh\",\n",
            "  \"pooler_output_size\": 1024,\n",
            "  \"qkv_bias\": false,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.51.2\"\n",
            "}\n",
            "\n",
            "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_cross_attention\": true,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"cross_attention_hidden_size\": 1024,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 12,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_decoder\": true,\n",
            "  \"layernorm_embedding\": true,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"trocr\",\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": false,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.51.2\",\n",
            "  \"use_cache\": false,\n",
            "  \"use_learned_position_embeddings\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "yolo_model\n",
        "token = 'YOUR TOKEN'\n",
        "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\",use_safetensors=True,token=token)\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"David-Magdy/TROCR_MASTER_V2\",use_safetensors=True,token=token).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gWGGzft35ULX"
      },
      "outputs": [],
      "source": [
        "def resize_image(image, target_size=(640, 640)):\n",
        "    \"\"\"\n",
        "    Resize an image to a target size (640x640) with padding if needed.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the input image.\n",
        "        target_size (tuple): Target size (width, height) in pixels.\n",
        "\n",
        "    Returns:\n",
        "        PIL.Image: Resized image with padding.\n",
        "    \"\"\"\n",
        "    aspect_ratio = image.width / image.height\n",
        "    if aspect_ratio > 1:\n",
        "        new_width = target_size[0]\n",
        "        new_height = int(new_width / aspect_ratio)\n",
        "    else:\n",
        "        new_height = target_size[1]\n",
        "        new_width = int(new_height * aspect_ratio)\n",
        "    img_resized = image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
        "    return ImageOps.pad(img_resized, target_size, color=(114, 114, 114))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EzmiFPgKePnv"
      },
      "outputs": [],
      "source": [
        "def extract(images):\n",
        "    \"\"\"\n",
        "    Processes a list of prescription images and extracts the associated text.\n",
        "\n",
        "    Args:\n",
        "        images (list of str): List of file paths to input prescription images.\n",
        "\n",
        "    Returns:\n",
        "        list of str: Extracted prescription texts corresponding to each input image.\n",
        "    \"\"\"\n",
        "    extracted_texts = []\n",
        "\n",
        "    for image_path in images:\n",
        "        try:\n",
        "\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "            resized_image = resize_image(image, target_size=(640, 640))\n",
        "\n",
        "\n",
        "            results = yolo_model.predict(\n",
        "                source=resized_image,\n",
        "                imgsz=640,\n",
        "                device=0 if torch.cuda.is_available() else \"cpu\",\n",
        "                save=False,\n",
        "                conf=0.5,\n",
        "                iou=0.6,\n",
        "                max_det=50\n",
        "            )\n",
        "\n",
        "\n",
        "            boxes = results[0].boxes\n",
        "            coords = boxes.xywhn.cpu().numpy()\n",
        "\n",
        "\n",
        "            sorted_indices = coords[:, 1].argsort()\n",
        "            sorted_coords = coords[sorted_indices]\n",
        "\n",
        "\n",
        "            img_width, img_height = 640, 640\n",
        "            crops = []\n",
        "            for coord in sorted_coords:\n",
        "                x_center, y_center, width, height = coord\n",
        "                x_min = int((x_center - width / 2) * img_width)\n",
        "                x_max = int((x_center + width / 2) * img_width)\n",
        "                y_min = int((y_center - height / 2) * img_height)\n",
        "                y_max = int((y_center + height / 2) * img_height)\n",
        "                crop = resized_image.crop((x_min, y_min, x_max, y_max))\n",
        "\n",
        "                crop = ImageOps.pad(crop, (384, 384), color=(255, 255, 255))\n",
        "                crops.append(crop)\n",
        "\n",
        "\n",
        "            extracted_text = \" \"\n",
        "            for crop in crops:\n",
        "                pixel_values = processor(crop, return_tensors=\"pt\").pixel_values.to(device)\n",
        "                generated_ids = model.generate(pixel_values)\n",
        "                text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "                extracted_text+=text+\" \"\n",
        "\n",
        "\n",
        "\n",
        "            extracted_texts.append(extracted_text)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {image_path}: {e}\")\n",
        "            extracted_texts.append(\"\")\n",
        "\n",
        "    return extracted_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ac2lYtTP2IjI"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from symspellpy import SymSpell, Verbosity\n",
        "\n",
        "\n",
        "drug_file =\"YOUR DRUG FILE PATH\"\n",
        "drug_df = pd.read_excel(drug_file)\n",
        "\n",
        "\n",
        "drug_dict = dict(zip(drug_df['text'].astype(str), drug_df['medicine']))\n",
        "\n",
        "\n",
        "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
        "\n",
        "\n",
        "for term in drug_dict.keys():\n",
        "    sym_spell.create_dictionary_entry(term, 1)\n",
        "\n",
        "def is_entirely_arabic(word):\n",
        "    \"\"\"Returns True if the entire word is Arabic letters only.\"\"\"\n",
        "    return all('\\u0600' <= ch <= '\\u06FF' for ch in word if ch.isalpha())\n",
        "\n",
        "def remove_arabic(text):\n",
        "    \"\"\"Remove Arabic characters from a word.\"\"\"\n",
        "    return re.sub(r'[\\u0600-\\u06FF]', '', text)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    1. Converts English numbers between Arabic words into Arabic numerals but keeps spacing (e.g., \"كل 8 ساعات\" → \"كل ٨ ساعات\").\n",
        "    \"\"\"\n",
        "\n",
        "    english_to_arabic_numbers = str.maketrans(\"0123456789\", \"٠١٢٣٤٥٦٧٨٩\")\n",
        "\n",
        "\n",
        "    def convert_numbers(match):\n",
        "        return f\"{match.group(1)} {match.group(2).translate(english_to_arabic_numbers)} {match.group(3)}\"\n",
        "\n",
        "    text = re.sub(r'([\\u0600-\\u06FF])\\s*([\\d]+)\\s*([\\u0600-\\u06FF])', convert_numbers, text)\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "def correct_term_symspell(text, sym_spell, max_distance=2):\n",
        "    \"\"\"Correction using SymSpell (edit distance-based).\"\"\"\n",
        "    text = str(text).strip()\n",
        "    suggestions = sym_spell.lookup(text, Verbosity.TOP, max_edit_distance=max_distance)\n",
        "\n",
        "    if suggestions:\n",
        "\n",
        "        return suggestions[0].term\n",
        "    else:\n",
        "        if is_entirely_arabic(text)== False:\n",
        "            text = remove_arabic(text)\n",
        "        print(f\"no suggestion for {text}\")\n",
        "        return text\n",
        "\n",
        "def process_text(text):\n",
        "    \"\"\"\n",
        "    Tokenizes input text, applies SymSpell correction per word, and checks medicine classification.\n",
        "    Then, groups medicine words together and pairs them with instructions.\n",
        "    Ensures that medicine names always appear first in the final pairs.\n",
        "    \"\"\"\n",
        "    text = preprocess_text(text)\n",
        "    words = re.findall(r'\\b\\w+\\b', text)\n",
        "\n",
        "\n",
        "    corrected_words = []\n",
        "\n",
        "\n",
        "    for word in words:\n",
        "        corrected_word = correct_term_symspell(word, sym_spell)\n",
        "        is_medicine = drug_dict.get(corrected_word, 1)\n",
        "        corrected_words.append((corrected_word, is_medicine))\n",
        "\n",
        "\n",
        "    grouped_pairs = []\n",
        "    current_group = []\n",
        "    previous_type = None\n",
        "\n",
        "    for word, is_medicine in corrected_words:\n",
        "        if is_medicine == previous_type or previous_type is None:\n",
        "            current_group.append(word)\n",
        "        else:\n",
        "\n",
        "            if previous_type is not None:\n",
        "                grouped_pairs.append((\" \".join(current_group), previous_type))\n",
        "            current_group = [word]\n",
        "        previous_type = is_medicine\n",
        "\n",
        "\n",
        "    if current_group:\n",
        "        grouped_pairs.append((\" \".join(current_group), previous_type))\n",
        "\n",
        "    return grouped_pairs\n",
        "\n",
        "def submit(images):\n",
        "    \"\"\"\n",
        "    Processes the text into (word, is_medicine) pairs.\n",
        "    Then groups every two consecutive items into a pair,\n",
        "    placing the medicine-type word first in the pair.\n",
        "    If an odd number of elements exists, the last one is paired with an empty string.\n",
        "    \"\"\"\n",
        "    pairs_per_image = []\n",
        "    text = extract(images)\n",
        "    for text in text:\n",
        "      items = process_text(text)\n",
        "      print(items)\n",
        "      final_pairs = []\n",
        "\n",
        "      i = 0\n",
        "      while i < len(items):\n",
        "          first = items[i]\n",
        "          second = items[i + 1] if i + 1 < len(items) else (\"\", -1)\n",
        "\n",
        "\n",
        "          if first[1] == 1:\n",
        "              pair = (first[0], second[0])\n",
        "          elif second[1] == 1:\n",
        "              pair = (second[0], first[0])\n",
        "          else:\n",
        "              pair = (first[0], second[0])\n",
        "\n",
        "          final_pairs.append(pair)\n",
        "          i += 2\n",
        "      pairs_per_image.append(final_pairs)\n",
        "\n",
        "    return pairs_per_image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWoVOqdfWZsm",
        "outputId": "b9ac9d2d-8fb3-4962-98d1-a63836c7d9b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 640x640 6 texts, 12.4ms\n",
            "Speed: 2.9ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "no suggestion for باراسيتامول\n",
            "[('Mupirocin', 1), ('كل ١٢ ساعه', 0), ('باراسيتامول', 1), ('قبل الفطار', 0), ('Hydrocortisone', 1), ('مرتين يوميا', 0)]\n"
          ]
        }
      ],
      "source": [
        "path = \"IMAGE FILE PATH\"\n",
        "\n",
        "ret = submit([path])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClGdk602WLXH",
        "outputId": "11095435-c638-4a52-ddb7-269303b6194d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Mupirocin', 'كل ١٢ ساعه'), ('باراسيتامول', 'قبل الفطار'), ('Hydrocortisone', 'مرتين يوميا')]\n"
          ]
        }
      ],
      "source": [
        "for results in ret:\n",
        "  print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UQT26IdY1Fz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "deeplearning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
